{"cells":[{"cell_type":"markdown","metadata":{"id":"gm6BOa1ViWo7"},"source":["# Using several classifiers and tuning parameters - Parameters grid\n","[From official `scikit-learn` documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html)\n","\n","Adapted by Claudio Sartori\n","\n","Example of usage of the ***model selection*** features of `scikit-learn` and comparison of several classification methods.\n","1. import a sample dataset \n","1. split the dataset into two parts: train and test\n","    - the *train* part will be used for training and validation (i.e. for *development*)\n","    - the *test* part will be used for test (i.e. for *evaluation*)\n","    - the fraction of test data will be _ts_ (a value of your choice between 0.2 and 0.5)\n","1. the function `GridSearchCV` iterates a cross validation experiment to train and test a model with different combinations of paramater values\n","    - for each parameter we set a list of values to test, the function will generate all the combinations\n","    - we choose a *score function* which will be used for the optimization\n","        - e.g. `accuracy_score`, `precision_score`, `cohen_kappa_score`, `f1_score`, see this [page](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for reference\n","    - the output is a dictionary containing \n","        - the set of parameters which maximize the score \n","        - the test scores\n","1. prepare the parameters for the grid\n","    - it is a list of dictionaries\n","1. set the parameters by cross validation and the *score functions* to choose from\n","1. Loop on scores and, for each score, loop on the model labels (see details below)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ly2DgKJPiWpA","outputId":"813c7119-8865-43fe-8fe3-3f54be46e852","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672651369361,"user_tz":-60,"elapsed":1400,"user":{"displayName":"Jacopo D'Abramo","userId":"10232214411039325967"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n","@author: scikit-learn.org and Claudio Sartori\n","\n"]}],"source":["\"\"\"\n","http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n","@author: scikit-learn.org and Claudio Sartori\n","\"\"\"\n","import warnings\n","warnings.filterwarnings('ignore') # uncomment this line to suppress warnings\n","\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.svm import SVC\n","from sklearn.linear_model import Perceptron\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n","\n","print(__doc__) # print information included in the triple quotes at the beginning\n","\n","# Loading a standard dataset\n","#dataset = datasets.load_digits()\n","#dataset = datasets.fetch_olivetti_faces()\n","#dataset = datasets.fetch_covtype()\n","dataset = datasets.load_iris()\n","#dataset = datasets.load_wine()\n","#dataset = datasets.load_breast_cancer()"]},{"cell_type":"markdown","metadata":{"id":"c9iKvhKtiWpB"},"source":["### Prepare the environment\n","The `dataset` module contains, among others, a few sample datasets.\n","\n","See this [page](http://scikit-learn.org/stable/datasets/index.html) for reference\n","\n","Prepare the data and the target in X and y. Set `ts`. Set the random state to 42"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YWWS9whiWpC"},"outputs":[],"source":["X = dataset.data\n","y = dataset.target\n","ts = 0.3\n","random_state = 42"]},{"cell_type":"markdown","metadata":{"id":"3w2d8CWRiWpC"},"source":["Split the dataset into the train and test parts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VdI7jvoiWpD","outputId":"48d75de5-d2e3-4256-f457-626608046807","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672652154088,"user_tz":-60,"elapsed":244,"user":{"displayName":"Jacopo D'Abramo","userId":"10232214411039325967"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(112, 4)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,random_state = 1)\n","print(Xtrain.shape)"]},{"cell_type":"markdown","metadata":{"id":"Rao2vnw4iWpD"},"source":["The code below is intended to ease the remainder of the exercise"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXmsSz_qiWpD"},"outputs":[],"source":["model_lbls = [\n","              'dt', \n","              'nb', \n","              'lp', \n","              'svc', \n","             'knn',\n","             'adb',\n","             'rf',\n","            ]\n","\n","# Set the parameters by cross-validation\n","tuned_param_dt = [{'max_depth': [*range(1,20)]}]\n","tuned_param_nb = [{'var_smoothing': [10, 1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-07, 1e-8, 1e-9, 1e-10]}]\n","tuned_param_lp = [{'early_stopping': [True]}]\n","tuned_param_svc = [{'kernel': ['rbf'], \n","                    'gamma': [1e-3, 1e-4],\n","                    'C': [1, 10, 100, 1000],\n","                    },\n","                    {'kernel': ['linear'],\n","                     'C': [1, 10, 100, 1000],                     \n","                    },\n","                   ]\n","tuned_param_knn =[{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n","tuned_param_adb = [{'n_estimators':[20,30,40,50],\n","                   'learning_rate':[0.5,0.75,1,1.25,1.5]}]\n","tuned_param_rf = [{'max_depth': [*range(5,15)],\n","                   'n_estimators':[*range(10,100,10)]}]\n","\n","models = {\n","    'dt': {'name': 'Decision Tree       ',\n","           'estimator': DecisionTreeClassifier(), \n","           'param': tuned_param_dt,\n","          },\n","    'nb': {'name': 'Gaussian Naive Bayes',\n","           'estimator': GaussianNB(),\n","           'param': tuned_param_nb\n","          },\n","    'lp': {'name': 'Linear Perceptron   ',\n","           'estimator': Perceptron(),\n","           'param': tuned_param_lp,\n","          },\n","    'svc':{'name': 'Support Vector      ',\n","           'estimator': SVC(), \n","           'param': tuned_param_svc\n","          },\n","    'knn':{'name': 'K Nearest Neighbor ',\n","           'estimator': KNeighborsClassifier(),\n","           'param': tuned_param_knn\n","       },\n","       'adb':{'name': 'AdaBoost           ',\n","           'estimator': AdaBoostClassifier(),\n","           'param': tuned_param_adb\n","          },\n","    'rf': {'name': 'Random forest       ',\n","           'estimator': RandomForestClassifier(),\n","           'param': tuned_param_rf\n","          }\n","\n","}\n","\n","scores = ['precision', 'recall']"]},{"cell_type":"markdown","metadata":{"id":"h_wQqw-MiWpE"},"source":["### The function below groups all the outputs\n","Write a function which has as parameter the fitted model and uses the components of the fitted model to inspect the results of the search with the parameters grid.\n","\n","The components are:<br>\n","`model.best_params_`<br>\n","`model.cv_results_['mean_test_score']`<br>`\n","model.cv_results_['std_test_score']`<br>\n","`model.cv_results_['params']`\n","\n","The classification report is generated by the function imported above from sklearn.metrics, which takes as argument the true and the predicted test labels.\n","\n","The +/- in the results is obtained doubling the `std_test_score`\n","\n","The function will be used to print the results for each set of parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTJS5j0WiWpE"},"outputs":[],"source":["def print_results(model):\n","    print(\"Best parameters set found on train set:\")\n","    print()\n","    # if best is linear there is no gamma parameter\n","    print(model.best_params_)\n","    print()\n","    print(\"Grid scores on train set:\")\n","    print()\n","    means = model.cv_results_['mean_test_score']\n","    stds = model.cv_results_['std_test_score']\n","    params = model.cv_results_['params']\n","    for mean, std, params_tuple in zip(means, stds, params):\n","        print(\"%0.3f (+/-%0.03f) for %r\"\n","              % (mean, std * 2, params_tuple))\n","    print()\n","    print(\"Detailed classification report for the best parameter set:\")\n","    print()\n","    print(\"The model is trained on the full train set.\")\n","    print(\"The scores are computed on the full test set.\")\n","    print()\n","    y_true, y_pred = ytest, model.predict(Xtest)\n","    print(classification_report(y_true, y_pred))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"ArgdSt6fiWpF"},"source":["### Loop on scores and, for each score, loop on the model labels\n","- iterate varying the score function\n","    1. iterate varying the classification model among Decision Tree, Naive Bayes, Linear Perceptron, Support Vector, AdaBoost, Random Forest and KNN\n","        - activate the *grid search*\n","            1. the resulting model will be the best one according to the current score function\n","        - print the best parameter set and the results for each set of parameters using the above defined function\n","        - print the classification report\n","        - store the `.best score_` in a dictionary for a final report\n","    1. print the final report for the current *score funtion*"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"2EOXJUjgiWpF","outputId":"4968e69e-6162-4129-ea9a-41e9cf2ffcbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672652635123,"user_tz":-60,"elapsed":64671,"user":{"displayName":"Jacopo D'Abramo","userId":"10232214411039325967"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Tuning hyper-parameters for  precision\n","Trying model dt\n","Best parameters set found on train set:\n","\n","{'max_depth': 1}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'max_depth': 1}\n","nan (+/-nan) for {'max_depth': 2}\n","nan (+/-nan) for {'max_depth': 3}\n","nan (+/-nan) for {'max_depth': 4}\n","nan (+/-nan) for {'max_depth': 5}\n","nan (+/-nan) for {'max_depth': 6}\n","nan (+/-nan) for {'max_depth': 7}\n","nan (+/-nan) for {'max_depth': 8}\n","nan (+/-nan) for {'max_depth': 9}\n","nan (+/-nan) for {'max_depth': 10}\n","nan (+/-nan) for {'max_depth': 11}\n","nan (+/-nan) for {'max_depth': 12}\n","nan (+/-nan) for {'max_depth': 13}\n","nan (+/-nan) for {'max_depth': 14}\n","nan (+/-nan) for {'max_depth': 15}\n","nan (+/-nan) for {'max_depth': 16}\n","nan (+/-nan) for {'max_depth': 17}\n","nan (+/-nan) for {'max_depth': 18}\n","nan (+/-nan) for {'max_depth': 19}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.00      0.00      0.00        16\n","           2       0.36      1.00      0.53         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.45      0.67      0.51        38\n","weighted avg       0.43      0.58      0.47        38\n","\n","\n","Trying model nb\n","Best parameters set found on train set:\n","\n","{'var_smoothing': 10}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'var_smoothing': 10}\n","nan (+/-nan) for {'var_smoothing': 1}\n","nan (+/-nan) for {'var_smoothing': 0.1}\n","nan (+/-nan) for {'var_smoothing': 0.01}\n","nan (+/-nan) for {'var_smoothing': 0.001}\n","nan (+/-nan) for {'var_smoothing': 0.0001}\n","nan (+/-nan) for {'var_smoothing': 1e-05}\n","nan (+/-nan) for {'var_smoothing': 1e-06}\n","nan (+/-nan) for {'var_smoothing': 1e-07}\n","nan (+/-nan) for {'var_smoothing': 1e-08}\n","nan (+/-nan) for {'var_smoothing': 1e-09}\n","nan (+/-nan) for {'var_smoothing': 1e-10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.00      0.00      0.00        16\n","           2       0.36      1.00      0.53         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.45      0.67      0.51        38\n","weighted avg       0.43      0.58      0.47        38\n","\n","\n","Trying model lp\n","Best parameters set found on train set:\n","\n","{'early_stopping': True}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'early_stopping': True}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.68      1.00      0.81        13\n","           1       0.00      0.00      0.00        16\n","           2       0.47      1.00      0.64         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.39      0.67      0.49        38\n","weighted avg       0.35      0.58      0.43        38\n","\n","\n","Trying model svc\n","Best parameters set found on train set:\n","\n","{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1, 'kernel': 'linear'}\n","nan (+/-nan) for {'C': 10, 'kernel': 'linear'}\n","nan (+/-nan) for {'C': 100, 'kernel': 'linear'}\n","nan (+/-nan) for {'C': 1000, 'kernel': 'linear'}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.93      1.00      0.96        13\n","           1       0.00      0.00      0.00        16\n","           2       0.38      1.00      0.55         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.43      0.67      0.50        38\n","weighted avg       0.41      0.58      0.46        38\n","\n","\n","Trying model knn\n","Best parameters set found on train set:\n","\n","{'n_neighbors': 1}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'n_neighbors': 1}\n","nan (+/-nan) for {'n_neighbors': 2}\n","nan (+/-nan) for {'n_neighbors': 3}\n","nan (+/-nan) for {'n_neighbors': 4}\n","nan (+/-nan) for {'n_neighbors': 5}\n","nan (+/-nan) for {'n_neighbors': 6}\n","nan (+/-nan) for {'n_neighbors': 7}\n","nan (+/-nan) for {'n_neighbors': 8}\n","nan (+/-nan) for {'n_neighbors': 9}\n","nan (+/-nan) for {'n_neighbors': 10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       1.00      1.00      1.00        16\n","           2       1.00      1.00      1.00         9\n","\n","    accuracy                           1.00        38\n","   macro avg       1.00      1.00      1.00        38\n","weighted avg       1.00      1.00      1.00        38\n","\n","\n","Trying model adb\n","Best parameters set found on train set:\n","\n","{'learning_rate': 0.5, 'n_estimators': 20}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 50}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       1.00      0.94      0.97        16\n","           2       0.90      1.00      0.95         9\n","\n","    accuracy                           0.97        38\n","   macro avg       0.97      0.98      0.97        38\n","weighted avg       0.98      0.97      0.97        38\n","\n","\n","Trying model rf\n","Best parameters set found on train set:\n","\n","{'max_depth': 5, 'n_estimators': 10}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 90}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       1.00      0.94      0.97        16\n","           2       0.90      1.00      0.95         9\n","\n","    accuracy                           0.97        38\n","   macro avg       0.97      0.98      0.97        38\n","weighted avg       0.98      0.97      0.97        38\n","\n","\n","Summary of results for precision\n","Estimator\n","Decision Tree       \t - score:  nan%\n","Gaussian Naive Bayes\t - score:  nan%\n","Linear Perceptron   \t - score:  nan%\n","Support Vector      \t - score:  nan%\n","K Nearest Neighbor \t - score:  nan%\n","AdaBoost           \t - score:  nan%\n","Random forest       \t - score:  nan%\n","Tuning hyper-parameters for  recall\n","Trying model dt\n","Best parameters set found on train set:\n","\n","{'max_depth': 1}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'max_depth': 1}\n","nan (+/-nan) for {'max_depth': 2}\n","nan (+/-nan) for {'max_depth': 3}\n","nan (+/-nan) for {'max_depth': 4}\n","nan (+/-nan) for {'max_depth': 5}\n","nan (+/-nan) for {'max_depth': 6}\n","nan (+/-nan) for {'max_depth': 7}\n","nan (+/-nan) for {'max_depth': 8}\n","nan (+/-nan) for {'max_depth': 9}\n","nan (+/-nan) for {'max_depth': 10}\n","nan (+/-nan) for {'max_depth': 11}\n","nan (+/-nan) for {'max_depth': 12}\n","nan (+/-nan) for {'max_depth': 13}\n","nan (+/-nan) for {'max_depth': 14}\n","nan (+/-nan) for {'max_depth': 15}\n","nan (+/-nan) for {'max_depth': 16}\n","nan (+/-nan) for {'max_depth': 17}\n","nan (+/-nan) for {'max_depth': 18}\n","nan (+/-nan) for {'max_depth': 19}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.00      0.00      0.00        16\n","           2       0.36      1.00      0.53         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.45      0.67      0.51        38\n","weighted avg       0.43      0.58      0.47        38\n","\n","\n","Trying model nb\n","Best parameters set found on train set:\n","\n","{'var_smoothing': 10}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'var_smoothing': 10}\n","nan (+/-nan) for {'var_smoothing': 1}\n","nan (+/-nan) for {'var_smoothing': 0.1}\n","nan (+/-nan) for {'var_smoothing': 0.01}\n","nan (+/-nan) for {'var_smoothing': 0.001}\n","nan (+/-nan) for {'var_smoothing': 0.0001}\n","nan (+/-nan) for {'var_smoothing': 1e-05}\n","nan (+/-nan) for {'var_smoothing': 1e-06}\n","nan (+/-nan) for {'var_smoothing': 1e-07}\n","nan (+/-nan) for {'var_smoothing': 1e-08}\n","nan (+/-nan) for {'var_smoothing': 1e-09}\n","nan (+/-nan) for {'var_smoothing': 1e-10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       0.00      0.00      0.00        16\n","           2       0.36      1.00      0.53         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.45      0.67      0.51        38\n","weighted avg       0.43      0.58      0.47        38\n","\n","\n","Trying model lp\n","Best parameters set found on train set:\n","\n","{'early_stopping': True}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'early_stopping': True}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.68      1.00      0.81        13\n","           1       0.00      0.00      0.00        16\n","           2       0.47      1.00      0.64         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.39      0.67      0.49        38\n","weighted avg       0.35      0.58      0.43        38\n","\n","\n","Trying model svc\n","Best parameters set found on train set:\n","\n","{'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n","nan (+/-nan) for {'C': 1, 'kernel': 'linear'}\n","nan (+/-nan) for {'C': 10, 'kernel': 'linear'}\n","nan (+/-nan) for {'C': 100, 'kernel': 'linear'}\n","nan (+/-nan) for {'C': 1000, 'kernel': 'linear'}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.93      1.00      0.96        13\n","           1       0.00      0.00      0.00        16\n","           2       0.38      1.00      0.55         9\n","\n","    accuracy                           0.58        38\n","   macro avg       0.43      0.67      0.50        38\n","weighted avg       0.41      0.58      0.46        38\n","\n","\n","Trying model knn\n","Best parameters set found on train set:\n","\n","{'n_neighbors': 1}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'n_neighbors': 1}\n","nan (+/-nan) for {'n_neighbors': 2}\n","nan (+/-nan) for {'n_neighbors': 3}\n","nan (+/-nan) for {'n_neighbors': 4}\n","nan (+/-nan) for {'n_neighbors': 5}\n","nan (+/-nan) for {'n_neighbors': 6}\n","nan (+/-nan) for {'n_neighbors': 7}\n","nan (+/-nan) for {'n_neighbors': 8}\n","nan (+/-nan) for {'n_neighbors': 9}\n","nan (+/-nan) for {'n_neighbors': 10}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       1.00      1.00      1.00        16\n","           2       1.00      1.00      1.00         9\n","\n","    accuracy                           1.00        38\n","   macro avg       1.00      1.00      1.00        38\n","weighted avg       1.00      1.00      1.00        38\n","\n","\n","Trying model adb\n","Best parameters set found on train set:\n","\n","{'learning_rate': 0.5, 'n_estimators': 20}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 0.5, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 0.75, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 1, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 1.25, 'n_estimators': 50}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 20}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 30}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 40}\n","nan (+/-nan) for {'learning_rate': 1.5, 'n_estimators': 50}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       1.00      0.94      0.97        16\n","           2       0.90      1.00      0.95         9\n","\n","    accuracy                           0.97        38\n","   macro avg       0.97      0.98      0.97        38\n","weighted avg       0.98      0.97      0.97        38\n","\n","\n","Trying model rf\n","Best parameters set found on train set:\n","\n","{'max_depth': 5, 'n_estimators': 10}\n","\n","Grid scores on train set:\n","\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 5, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 6, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 7, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 8, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 9, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 10, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 11, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 12, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 13, 'n_estimators': 90}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 10}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 20}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 30}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 40}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 50}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 60}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 70}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 80}\n","nan (+/-nan) for {'max_depth': 14, 'n_estimators': 90}\n","\n","Detailed classification report for the best parameter set:\n","\n","The model is trained on the full train set.\n","The scores are computed on the full test set.\n","\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        13\n","           1       1.00      0.94      0.97        16\n","           2       0.90      1.00      0.95         9\n","\n","    accuracy                           0.97        38\n","   macro avg       0.97      0.98      0.97        38\n","weighted avg       0.98      0.97      0.97        38\n","\n","\n","Summary of results for recall\n","Estimator\n","Decision Tree       \t - score:  nan%\n","Gaussian Naive Bayes\t - score:  nan%\n","Linear Perceptron   \t - score:  nan%\n","Support Vector      \t - score:  nan%\n","K Nearest Neighbor \t - score:  nan%\n","AdaBoost           \t - score:  nan%\n","Random forest       \t - score:  nan%\n"]}],"source":["results_short={}\n","for score in scores:\n","    print(\"Tuning hyper-parameters for \",score)\n","\n","    for m in model_lbls:\n","        print(\"Trying model\",m)\n","        \n","        clf = GridSearchCV(models[m]['estimator'],models[m]['param'], cv=5,\n","                           scoring=score, \n","                           return_train_score = False,\n","                           n_jobs = 2, # this allows using multi-cores\n","                           )\n","\n","        clf.fit(Xtrain, ytrain)\n","        print_results(clf)\n","        results_short[m] = clf.best_score_\n","    print(\"Summary of results for {}\".format(score))\n","    print(\"Estimator\")\n","    for m in results_short.keys():\n","        print(\"{}\\t - score: {:4.2}%\".format(models[m]['name'], results_short[m]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvuJj8wmiWpF"},"outputs":[],"source":[]}],"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3.7.13 ('res')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"vscode":{"interpreter":{"hash":"7650257707f3238d5df88771c66da47b78c5077cb779498608c81dcf9deec5b5"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}